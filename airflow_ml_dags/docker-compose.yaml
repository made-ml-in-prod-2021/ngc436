version: '3.7'
# ====================================== AIRFLOW ENVIRONMENT VARIABLES =======================================
x-environment: &airflow_environment
  - AIRFLOW__CORE__EXECUTOR=LocalExecutor
  - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
  - AIRFLOW__CORE__LOAD_EXAMPLES=True
  - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://airflow:airflow@postgres:5432/airflow
  - AIRFLOW__CORE__STORE_DAG_CODE=True
  - AIRFLOW__CORE__STORE_SERIALIZED_DAGS=True
  - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
  - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}


x-airflow-image: &airflow_image apache/airflow:latest-python3.8
# ====================================== /AIRFLOW ENVIRONMENT VARIABLES ======================================
services:
  postgres:
    image: postgres:12-alpine
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"
  init:
    build:
      context: images/airflow-docker
      args:
        AIRFLOW_BASE_IMAGE: *airflow_image
    image: airflow-docker
    depends_on:
      - postgres
    environment: *airflow_environment
    entrypoint: /bin/bash
    command: -c 'airflow db init && airflow users create --username admin --password admin --firstname Anonymous --lastname Admin --role Admin --email admin@example.org'

  webserver:
    build:
      context: images/airflow-docker
      args:
        AIRFLOW_BASE_IMAGE: *airflow_image
    image: airflow-docker

    restart: always
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    volumes:
      - logs:/opt/airflow/logs
    environment: *airflow_environment
    command: webserver

  scheduler:
    build:
      context: images/airflow-docker
      args:
        AIRFLOW_BASE_IMAGE: *airflow_image
    image: airflow-docker

    restart: always
    depends_on:
      - postgres
    volumes:
      - logs:/opt/airflow/logs
      - ./dags/:/opt/airflow/dags/
      - ./data/:/opt/airflow/data/
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/data:/data
    environment: *airflow_environment
    command: scheduler

  mlflow-db:
    restart: always
    image: mysql/mysql-server:5.7.28
    ports:
      - "3306:3306"
    environment:
      - MYSQL_DATABASE=mlflow
      - MYSQL_USER=mlflow
      - MYSQL_PASSWORD=mlflow
      - MYSQL_ROOT_PASSWORD=mlflow
    volumes:
      - dbdata:/var/lib/mysql

  mlflow-webserver:
    build:
      context: images/mlflow-webserver
    restart: always
    image: mlflow-webserver
    depends_on:
      - mlflow-db
    ports:
      - "5000:5000"
    command: --backend-store-uri mysql+pymysql://mlflow:mlflow@mlflow-db:3306/mlflow --default-artifact-root /tmp/mlruns --host 0.0.0.0
    volumes:
      - /tmp/mlruns:/tmp/mlruns

  ml_base:
    build:
      context: images/airflow-ml-base
    image: airflow-ml-base
    restart: "no"

  data_generation:
    build:
      context: images/airflow-data-generation
    image: airflow-data-generation
    restart: "no"

  preprocess:
    build:
      context: images/airflow-preprocess
    image: airflow-preprocess
    restart: "no"

  train_test:
    build:
      context: images/airflow-train-test
    image: airflow-train-test
    restart: "no"

  ml_train:
    build:
      context: images/airflow-ml-train
    image: airflow-ml-train
    restart: "no"

  predict:
    build:
      context: images/airflow-predict
    image: airflow-predict
    restart: "no"

volumes:
  logs:
  dbdata:
